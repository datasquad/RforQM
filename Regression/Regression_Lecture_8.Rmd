---
title: "IV Estimators"
output: pdf_document

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning = FALSE)
```


# Preparing your workfile

We add the basic libraries needed for this week's work: 

```{r}
library(tidyverse)    # for almost all data handling tasks
library(readxl)       # to import Excel data
library(ggplot2)      # to produce nice graphiscs
library(stargazer)    # to produce nice results tables
library(haven)        # to import stata file
library(AER)          # access to HS robust standard errors
library(estimatr)     # use robust se
source("stargazer_HC.r")
```


# Introduction

In this script we will introduce the use of instrumental variables estimation. This is an important and popular technique to potentially reveal causal relationships between variables where simple regression analysis fails as one has to assume that the explanatory variable of interest (here education) is endogenous in a model attempting to explain variation in wages.
The data used are a classic dataset used in econometrics which you will find used in multiple econometrics textbooks. 

# Data Upload - and understanding data structure

Upload the data, which are saved in a STATA datafile (extension `.dta`). There is a function which loads STATA file. It is called `read_dta` and is supplied by the `haven` package.

```{r}
mroz <- read_dta("mroz.dta")
mroz <- as.data.frame(mroz)    # ensure data frame structure
names(mroz)
```

The variables have short descriptions:
1. inlf                     =1 if in labor force, 1975  
2. hours                    hours worked, 1975  
3. kidslt6                  # kids < 6 years  
4. kidsge6                  # kids 6-18  
5. age                      woman's age in yrs  
6. educ                     years of schooling  
7. wage                     estimated wage from earns., hours  
8. repwage                  reported wage at interview in 1976  
9. hushrs                   hours worked by husband, 1975  
10. husage                   husband's age  
11. huseduc                  husband's years of schooling  
12. huswage                  husband's hourly wage, 1975  
13. faminc                   family income, 1975  
14. mtr                      fed. marginal tax rate facing woman  
15. motheduc                 mother's years of schooling  
16. fatheduc                 father's years of schooling  
17. unem                     unem. rate in county of resid.  
18. city                     =1 if live in SMSA  
19. exper                    actual labor mkt exper  
20. nwifeinc                 (faminc - wage*hours)/1000  
21. lwage                    log(wage)  
22. expersq                  exper^2  

 
# A standard regression

Let's start by running a standard regression of log wages (`lwage`) as dependent variable and a respondents education (`educ`) as the explanatory variable.

But before we do this we shall ensure that we remove those observations from the dataset for which we do not have a measure of wage (or log(wage)).

```{r}
mroz <- mroz %>% filter(!is.na(lwage))
```

```{r}
ols <- lm(lwage~educ,data = mroz)
stargazer_HC(ols)
```

# The IV estimator

Let's consider a respondent's father's education as an instrument for education. We therefore run a first stage regression:

```{r}
iv_s1 <- lm(educ~fatheduc, data = mroz)
stargazer_HC(iv_s1)
```


What we learn from this is that the  (`fatheduc`) is indeed related to the `educ` variable. Hence we feel justified in using this in our IV regression. But do remember that you will have to make an argument why `fatheduc` is a valid instrument, we cannot formally show that it is unrelated to the error term.

```{r}
iv <- ivreg(lwage~educ|fatheduc,data=mroz)
stargazer_HC(iv)
```

We can show all three estimates in the same table (omitting the F statistic as this would make the table very wide).

```{r}
stargazer_HC(ols,iv,iv_s1, omit.stat = "f")
```

Clearly the estimates for the `educ` variable are substantially different when comparing `ols` and `iv`. We really only want to revert to the `iv` model if there is evidence that the `educ` variable is indeed endogenous. The standard test applied in this context is the Wu-Hausmann test of endogeneity (H0: `educ` is exogenous). The easiest way to obtain this is to call `summary(iv,diagnostics = TRUE)` where `iv` is the name we have given our IV regresison output:

```{r}
summary(iv, diagnostics = TRUE)
```

Note that from here you can read that the p-value for the Wu-Hausmann test is 0.117. So, for instance, at a 5% significance level we would not reject the null hypothesis that `educ` is actually exogenous. 

# Implications of the different estimators

Recall that the estimated coefficients are merely one draw from an underlying random distribution. The sampling distributions (i.e. our sample estimates of these unknown distributions) are shown in the following graph. The distributions for both are normal distributions where the mean is equal to the respective sample estimate and the sd, is taken from the regression outputs.

```{r}
#pdf("Lecture8plot_R.pdf",width = 5.5, height = 4) # uncomment to save as pdf
x <- seq(-0.02, 0.16, length=1000)
y_ols <- dnorm(x, mean=0.1086, sd=0.0134)
y_iv <- dnorm(x, mean = 0.0592, sd = 0.0369)
plot(x, y_ols, type="l", col="blue", lwd=2, axes = FALSE,
     ylab = "Sampling Distribution", main = "OLS and IV estimator")
lines(x,y_iv,col="green", lwd = 2)
axis(side = 1, at = c(-0.01,0.06,0.08,0.11,0.13,0.14))
#dev.off() # uncomment to save as pdf
```

You can tell from these that the OLS estimate and its implied distribution suggests that a value of 0 is very unlikely whereas the sampling distribution of the IV estimator does associate significant probability to values of 0 or smaller.