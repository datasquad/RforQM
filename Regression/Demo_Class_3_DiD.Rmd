---
title: "Demo Class 3"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning = FALSE)
```

This is the code to implement the work for Demo Class 3

* estimate a DiD model
* apply cluster robust standard errors

# Introduction

We are going to estimate the following two models

# Preparing your workfile

We add the basic libraries needed for this week's work: 

```{r}
library(tidyverse)    # for almost all data handling tasks
library(ggplot2)      # to produce nice graphics
library(stargazer)    # to produce nice results tables
library(haven)        # to import stata file
library(ggplot2)      # for graphs
library(AER)          # access to HS robust standard errors
library(plm)          # for panel data methods
library(sandwich)     # for cluster robust se
library(lmtest)
library(coefplot)     # to create coefficient plots

```

You should also save the separately supplied `stargazer_HC.r` file in your working directory. This will make it straightforward to estimate and compare regressions with robust standard errors. Once you have done that you should include the following line into your code which basically makes this function available to you.

```{r}
source("stargazer_HC.r")  # includes the robust regression 
```

This has worked if you can see it loaded into your environment as a function.



# Data Prep
Read the data.

```{r}
data <- read_dta("did_4.dta") 
data <- as.data.frame(data)
```

Let's look at the data file.

```{r}
str(data) 
names(data)
summary(data)
```

We will convert some variables to factor (categorical) variables

```{r}
data$year <- as_factor(data$year)
data$w <- as_factor(data$w)
data$d <- as_factor(data$d)
levels(data$d) <- c("control","treated")
data$id <- as_factor(data$id)

```

# Investigate the Panel Structure

Let's define the dataset as a panel dataset with `id` as the cross-sectional identifier and 1year1 as the time identifier.

```{r}
pdata <- pdata.frame(data, index = c("id","year")) # defines the panel dimensions
```
The `plm` library we imported has a useful little function to check whether the panel is balanced.

```{r}
is.pbalanced(pdata)
```

This has returned `TRUE` indicating that it is indeed balanced. As there are four years of data, this means that we have 513 units of observation (4 x 513 = 2052).

Let's look again at the summary statistics for the variables `w` "treated in a particular year" and `d` "ever treated". 

```{r}
summary(data[,c("w","d")])
```

You can see that 536 observations belong to individuals ever treated. As we have four years of observations for each individual this implies that $S_1 = 134$ individuals were ever treated. The remainder, $S_0=379$ is the size of the control group. The number of observations in treatment are only 268. Exactly half. this is best understood if we look at the data for one of the observations in the treatment group (`id=3591`):

```{r}

pdata[data$id==3591,c("id","year","w","d","post")]
```

You can see that this individual was treated in two of the years (2014 and 2015). This is the same for all treated individuals. The variable `w` is therefore the equivalent to the "TREATxPOST" or here `d*post` variable. 

# Estimate the TWFE model

Let us estimate the TWFE model but when we output the result we shall only show the coefficient to `w`, our policy estimate.

```{r}
mod1 <- lm(logy~id+year+w, data = pdata)
stargazer(mod1, keep = "w", type="text", digits = 6) 
```

If you want to estimate cluster (here by `id`) robust standard errors we use the following function

```{r}
mod1_cr_se <- sqrt(diag(vcovCL(mod1, cluster = ~ id)))
stargazer(mod1, keep = "w", type="text", se=list(mod1_cr_se), digits = 6)
```

You can see that there is a difference in the standard error.

Let us now replace the `id`-level fixed effect by merely adding the ever treated dummy `d`

```{r}
mod2 <- lm(logy~year+d+w, data = pdata)
mod2_cr_se <- sqrt(diag(vcovCL(mod2, cluster = ~ id)))
stargazer(mod2, type="text", se=list(mod2_cr_se), digits = 6)
```

As this model only estimates 6 parameters we can actually look at all estimated coefficients. The standard errors are incorrect as we are actually estimating $S+T-1+1=517$ coefficients. The correct standard errors are the ones from `mod1`.

From the last model we can get the fitted values.

```{r}
pdata$logyhat <- mod2$fitted.values
```

Let us plot the predicted `logyhat`, separate for the treatment and control group. We use the second version, as it basically averages across individuals in year/treatment groups.

```{r}
p1 <- ggplot(pdata,aes(x=year,y=logyhat,color=d)) + geom_point()  
p1
```

# TWFE -> Event Study

Now we create interactions between the ever treated variable `d` and the years. In order to nderstand what the following regression does we will actually calculate new variables into the dataset.

```{r}
pdata <- pdata %>%  mutate(d2013 = (year=="2013")*(d=="treated"),
                           d2014 = (year=="2014")*(d=="treated"),
                           d2015 = (year=="2015")*(d=="treated"))
```

Now we estimate the extended TWFE model. First with the individual fixed effects included, producing the correct standard errors.

```{r}
mod3 <- lm(logy~id+year+d2013+d2014+d2015, data = pdata)
mod3_cr_se <- sqrt(diag(vcovCL(mod3, cluster = ~ id)))
coef_keep = c("d2013","d2014","d2015")
stargazer(mod3, type="text", keep = coef_keep, se=list(mod3_cr_se), digits = 6)
```

Now using the algebraic trick (but incorrect standard errors)

```{r}
mod4 <- lm(logy~year+d+d2013+d2014+d2015, data = pdata)
mod4_cr_se <- sqrt(diag(vcovCL(mod4, cluster = ~ id)))
stargazer(mod4, type="text", se=list(mod4_cr_se), digits = 6)
```

```{r}
pdata$logyhat_mod4 <- mod4$fitted.values
```

Let us plot the predicted `logyhat`, separate for the treatment and control group.

```{r}
p2 <- ggplot(pdata,aes(x=year,y=logyhat_mod4,color=d)) + geom_point()  
p2
```

The most common way to display these results is by showing the coefficients of the `d` variable interacted with the years.

```{r}
coefplot(mod3, coefficients = coef_keep, innerCI = 0, horizontal = TRUE)
```

# Collapse the data to group means

data_collapse <- data %>% group_by(d,post)