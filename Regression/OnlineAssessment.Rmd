---
title: "R-work for Online Assessment"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning = FALSE)
student_view <- 'asis'   # set to 'hide' to not reveal output, 'asis' to show
solution_echo <- TRUE   # set to FALSE to not show full code, TRUE to show full code 
```

# Instructions

You should go through the code below and complete it. Keep the completed code and all the resulting output. With that information you will be able to answer the questions you will see in the online quiz. Every student will see a slightly different collection of questions (as we will draw 10 questions from a pool of questions with about 20 questions).

The type of questions you will see will be of four types. 

1) Questions that merely ask you to report output from your analysis. 

2) Some questions will ask you about R code. For instance you will see a lot of gaps (`XXXX`) in the code and questions may ask you how you had to complete the code to make the code work. Other questions may ask you what output a particular bit of code would produce. If you want to practice these sorts of questions you could practice on Datacamp.

3) The third type of questions will ask you understanding questions like "What is the meaning of an estimated coefficient?" "Is a particular coefficient statistically significant?"

4) We may be asked questions on general programming issues, like what is the meaning of an error message or how would you search for a particular piece of information.

# Preparing your workfile

We add the basic libraries needed for this week's work:

```{r}
library(tidyverse)    # for almost all data handling tasks
library(ggplot2)      # to produce nice graphiscs
library(stargazer)    # to produce nice results tables
library(haven)        # to import stata file
library(AER)          # access to HS robust standard errors
source("stargazer_HC.r")  # includes the robust regression display
```

# Introduction

The data are an extract from the [Understanding Society Survey](https://www.understandingsociety.ac.uk/) (formerly the British Household Survey Panel).

# Data Upload - and understanding data structure

Upload the data, which are saved in a STATA datafile (extension `.dta`). There is a function which loads STATA file. It is called `read_dta` and is supplied by the `haven` package. 

```{r, eval = FALSE}
data_USoc <- XXXX("20222_USoc_extract.dta")
data_USoc <- as.data.frame(XXXX)    # ensure data frame structure
names(XXXX)
```
```{r, echo = solution_echo}
data_USoc <- read_dta("20222_USoc_extract.dta")
data_USoc <- as.data.frame(data_USoc)    # ensure data frame structure
names(data_USoc)
```

Let us ensure that categorical variables are stored as `factor` variables. It is easiest to work with these in R.

```{r, eval  = FALSE}
data_USoc$region <- XXXX
data_USoc$male <- XXXX
data_USoc$degree <- XXXX
data_USoc$race <- XXXX
```
```{r, echo = solution_echo}
data_USoc$region <- as_factor(data_USoc$region)
data_USoc$male <- as_factor(data_USoc$male)
data_USoc$degree <- as_factor(data_USoc$degree)
data_USoc$race <- as_factor(data_USoc$race)
```

As we defined the `male` variable as a factor it has levels `male` and `female` (check `levels(data_USoc$male)` to confirm). It would be better to relabel the variable to `gender`.

```{r}
names(data_USoc)[names(data_USoc) == "male"] <- "gender"
```

The pay information (`paygu`) is provided as a measure of the (usual) gross pay per month. As workers work for varying numbers of hours per week (`jbhrs`) we divide the monthly pay by the approximate monthly hours (`4*jbhrs`). We shall also adjust for increasing price levels (as measured by `cpi`). These two adjustments leave us with an inflation adjusted hourly wage. We call this variable `hrpay` and also calculate the natural log of this variable (`lnhrpay`).

```{r, eval = FALSE}
data_USoc <- data_USoc %>%
              XXXX(hrpay = XXXX) %>%
              XXXX(lnhrpay = XXXX)
```
```{r, echo = solution_echo}
data_USoc <- data_USoc %>%
              mutate(hrpay = paygu/(jbhrs*4)/(cpi/100)) %>%
              mutate(lnhrpay = log(hrpay))
```

As we wanted to save these additional variables we assign the result of the operation to `data_USoc`.

We also want to use a measure of annual pay (`paygu*12/(cpi/100))`) and add this variable (`annualpay`) to the dataframe (`data_USoc`).

```{r, eval = FALSE}
data_USoc <- XXXX %>%
              XXXX
```
```{r, echo = solution_echo}
data_USoc <- data_USoc %>%
              mutate(annualpay = paygu*12/(cpi/100))
```

Here we will evaluate the relation between `lnhrpay` and `age`. Let's first summarise all numerical variables in our dataset, using the `stargazer` function. 

```{r, eval = FALSE}
XXXX
```
```{r, echo = solution_echo, results=student_view}
stargazer(data_USoc,type="latex")
```

You should find, for instance, that the mean value of the unemployment rate (`urate`) is 7.955 and the standard deviation for the `age` variable is 18.295.

For later purposes we will also need variables $age^2/100$ and $log(age)$. We now need to create these variables (`agesq` and `lnage`) and add them to the `data_USoc` dataframe.

```{r, eval = FALSE}
XXXX
mean(data_USoc$lnage)
```
```{r, echo = solution_echo, results=student_view}
data_USoc <- data_USoc %>%  
                mutate(agesq = age*age/100) %>% 
                mutate(lnage = log(age))
mean(data_USoc$lnage)
```

You should find the mean of `lnage` to be 3.744307.

# Data cleaning

We will now remove unusable observations from our `data_USoc` dataframe, in particular those observations which have missing (`NA`) data for `lnhrpay`. In addition to that we will also remove observations from males which are 66 years or older and females whose age is 61 years or older.

```{r, eval = FALSE}
data_USoc <- data_USoc %>% 
                XXXX
```
```{r, echo = solution_echo}
data_USoc <- data_USoc %>% 
                filter(!is.na(lnhrpay)) %>% 
                filter((gender == "male" & age < 66) | (gender == "female" & age < 61) )
```

You should end up with 56778 observations.

# Estimate regression models - Version 1

We shall estimate the following regression models (`mod1`)

\[lnhrpay = \beta_0 + \beta_1 ~ age + \beta_2 ~ agesq + u\]

and (`mod2`)

\[lnhrpay = \alpha_0 + \alpha_1 ~ lnage + u\]

```{r, eval = FALSE}
mod1 <- lm(XXXX ~ XXXX+XXXX, data = data_USoc)
mod2 <- lm(XXXX)
stargazer_HC(mod1,mod2)
```
```{r, echo = solution_echo, results = student_view}
mod1 <- lm(lnhrpay ~ age+agesq, data = data_USoc)
mod2 <- lm(lnhrpay ~ lnage, data = data_USoc)
stargazer_HC(mod1,mod2,type_out="latex")
```

You have done this correctly if you find that that your estimated constant for `mod1` is 0.560.

These are two ways of allowing `age` to be correlated with `lnhrpay`. Both are what we call parametric, either a quadratic relation or a logarithmic relation.

As we have lots of data we can do this in a more flexible way as well. We could basically produce a dummy variable for every age (ages are reported in full years only) an then include a dummy variable for each age. TO do this we will first have to create an age variable which treats age as a categorical, or in R terms factor variable. We shall call this `age_f`.

```{r}
data_USoc <- data_USoc %>% mutate(age_f = as.factor(age))
```

With `age_f` being a factor variable, it is now straightforward to include thsi factor variable into a regresison. We can either include a constant (`lnhrpay ~ age_f`) which will then use age = 16 as a base category, or we can estimate the model without a constant (`lnhrpay ~ age_f - 1`) in which case all age categories enter separately.

```{r, eval = FALSE}
mod3 <- lm(lnhrpay ~ age_f, data = data_USoc)
mod4 <- lm(lnhrpay ~ age_f -1, data = data_USoc)
stargazer_HC(mod3,mod4)
```
```{r, echo = solution_echo, results = student_view}
mod3 <- lm(lnhrpay ~ age_f, data = data_USoc)
mod4 <- lm(lnhrpay ~ age_f -1, data = data_USoc)
stargazer_HC(mod3,mod4,type_out="latex")
```

Let's compare the fitted values for `mod1`, `mod2` and `mod4`. First we add the predicted values to the dataframe. There are several ways to achieve this and I recommend you ask Dr. Google. Think carefully about the search terms.

```{r, eval = FALSE}
data_USoc$pred_mod1 <- XXXX
data_USoc$pred_mod2 <- XXXX
data_USoc$pred_mod4 <- XXXX
```
```{r,echo = solution_echo, results=student_view}
data_USoc$pred_mod1 <- mod1$fitted.values
data_USoc$pred_mod2 <- mod2$fitted.values
data_USoc$pred_mod4 <- mod4$fitted.values
```

Now we plot the predicted values for the three specifications. You should also change the Axis labels to "Predicted values" for the vertical axis, "Age (in Years)" for the horizontal axis and add a title ("Predicted Regression Model") to your picture. If you google you should find the appropriate commands. Think carefully about the search terms.

```{r, eval = FALSE}
ggplot(data_USoc, aes(x=age,y=pred_mod4)) +
  geom_point(color = "red") +
  geom_line(aes(y=pred_mod1),color = "blue") +
  geom_line(aes(y=pred_mod2),color = "darkorange") +
  XXXX +   # add code to give your plot a title
  XXXX     # add code to change the axis labels

```
```{r,echo = solution_echo, results=student_view, fig.show = student_view}
ggplot(data_USoc, aes(x=age,y=pred_mod4)) +
  geom_point(color = "red") +
  geom_line(aes(y=pred_mod1),color = "blue") +
  geom_line(aes(y=pred_mod2),color = "darkorange") +
  ggtitle("Predicted Regression Model") +
  ylab("Predicted values") +
  xlab("Age (in Years)") 

```

The fit of `mod4` is the most flexible specification as it uses a coefficient for each year. Specifications `mod1` and `mod2` models model the relationship between `age` and `lnhrpay` with one and two parameters respectively.

# Estimate regression models 2

Now we will estimate a quadratic model for `annualpay` (`annualpay ~ age + agesq`) on a subsets of data in order to compare these. When you know that you will be working with different subsets of data, the best way of doing that in R is to create a new factor variale (here `subset_ind`) which allows you to separate the data accordingly.

We will create two subgroups: 1) Males with a first degree and 2) Males with no degree. You may want to check the values of the `degree` variable in order to define these correctly.

```{r, eval = FALSE}
data_USoc$subset_ind <- "none"   # default group
data_USoc$subset_ind[data_USoc$gender == "male" & data_USoc$degree == "first degree"] <- "Male with first degree"
data_USoc$subset_ind[XXXX] <- "Male without first degree"  # select all males with no degree
data_USoc$subset_ind <- as.factor(data_USoc$subset_ind)
data_USoc %>% count(subset_ind)
```
```{r,echo = solution_echo, results=student_view}
data_USoc$subset_ind <- "none"   # default group
data_USoc$subset_ind[data_USoc$gender == "male" & data_USoc$degree == "first degree"] <- "Male with first degree"
data_USoc$subset_ind[data_USoc$gender == "male" & data_USoc$degree == "no degree"] <- "Male without first degree"
data_USoc$subset_ind <- as.factor(data_USoc$subset_ind)
data_USoc %>% count(subset_ind)
```
   
We will want to save the model predictions and for this purpose we pre-define a variable in which we will save the predictions.

```{r}
data_USoc$pred_mod5 <- 0    # set the prediction to 0 by default
```

Now we estimate the model for the male with first degree subgroup. Note that the `lm` function accepts a `subset` argument which allows you to select a subset of observations, such as the group of all males with first degree.

```{r, eval = FALSE}
mod5_md <- lm(XXXX ~ XXXX + XXXX, data = XXXX, subset = (subset_ind == XXXX))
stargazer_HC(XXXX)
data_USoc$pred_mod5[data_USoc$subset_ind==XXXX] <- mod5_md$fitted.values
```
```{r, echo = solution_echo, results=student_view}
mod5_md <- lm(annualpay ~ age + agesq, data = data_USoc, subset = (subset_ind == "Male with first degree"))
stargazer_HC(mod5_md,type_out="latex")
data_USoc$pred_mod5[data_USoc$subset_ind=="Male with first degree"] <- mod5_md$fitted.values
```

Now we repeat the same just for the group of males with no degree

```{r, eval=FALSE}
mod5_mnd <- XXXX
stargazer_HC(XXXX)
data_USoc$pred_mod5[XXXX] <- mod5_mnd$fitted.values
```
```{r, echo = solution_echo, results=student_view}
mod5_mnd <- lm(annualpay ~ age + agesq, data = data_USoc, subset = (subset_ind == "Male without first degree"))
stargazer_HC(mod5_mnd,type_out="latex")
data_USoc$pred_mod5[data_USoc$subset_ind=="Male without first degree"] <- mod5_mnd$fitted.values
```


Now we plot the predicted values for the two specifications. 

```{r, fig.show = student_view}
ggplot(data_USoc, aes(x=age,y=pred_mod5,color = subset_ind)) +
  geom_line() +
  ggtitle("Predicted Regression Model - Model 5") +
  ylab("Predicted values") +
  xlab("Age") 
```
You will see that we have the "none" category plotted as well (of course we didn't estimate this). You could remove these data before plotting 

```{r, fig.show = student_view}
data_temp <- data_USoc %>% filter(subset_ind != "none")  # remove observations with subset_ind == "none"
ggplot(data_temp, aes(x=age,y=pred_mod5,color = subset_ind)) +
  geom_line() +
  ggtitle("Predicted Regression Model - Model 5") +
  ylab("Predicted values") +
  xlab("Age") 
```

END OF INSTRUCTIONS