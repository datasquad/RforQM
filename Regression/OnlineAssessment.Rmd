---
title: "Introduction to Regression Analysis - Multivariate Regression"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning = FALSE)
```


# Preparing your workfile

We add the basic libraries needed for this week's work:

```{r}
library(tidyverse)    # for almost all data handling tasks
library(ggplot2)      # to produce nice graphiscs
library(stargazer)    # to produce nice results tables
library(haven)        # to import stata file
library(AER)          # access to HS robust standard errors
source("stargazer_HC.r")  # includes the robust regression display
```


# Introduction

The data are an extract from the [Understanding Society Survey](https://www.understandingsociety.ac.uk/) (formerly the British Household Survey Panel).

# Data Upload - and understanding data structure

Upload the data, which are saved in a STATA datafile (extension `.dta`). There is a function which loads STATA file. It is called `read_dta` and is supplied by the `haven` package.

```{r}
data_USoc <- read_dta("20222_USoc_extract.dta")
data_USoc <- as.data.frame(data_USoc)    # ensure data frame structure
names(data_USoc)
```

Let us ensure that categorical variables are stored as `factor` variables. It is easiest to work with these in R.

```{r}
data_USoc$region <- as_factor(data_USoc$region)
data_USoc$male <- as_factor(data_USoc$male)
data_USoc$degree <- as_factor(data_USoc$degree)
data_USoc$race <- as_factor(data_USoc$race)
```

The pay information (`paygu`) is provided as a measure of the (usual) gross pay per month. As workers work for varying numbers of hours per week (`jbhrs`) we divide the monthly pay by the approximate monthly hours (`4*jbhrs`). We shall also adjust for increasing price levels (as measured by `cpi`). These two adjustments leave us with an inflation adjusted hourly wage. We call this variable `hrpay` and also calculate the natural log of this variable (`lnhrpay`).

```{r}
data_USoc <- data_USoc %>%
              mutate(hrpay = paygu/(jbhrs*4)/(cpi/100)) %>%
              mutate(lnhrpay = log(hrpay))
```

As we wanted to save these additional variables we assign the result of the operation to `data_USoc`.

In this lecture we will use the firmsize variable `mfsize9`. When we import the data from the STATA dta file, the variables inherit certain attributes. You can see them if you look at the structure of the dataframe (`str(data_USoc)`). One of the attributes is the label and it contains a little bit of information on the variable.

```{r}
attr(data_USoc$mfsize9,"label")
```

And we can also look at the unique values this variable takes

```{r}
unique(data_USoc$mfsize9)
```

You can see that there are 9 possible values (which is where the 9 in the name comes from). Each respondent records the size of the firm they work for, but we do not observe the actual size. There are buckets or bins for firm sizes, e.g. 51 to 100, 101 to 200, 201 to 500, etc. And the number we see is the mid-value of the respective bucket into which a firm falls.

```{r}
data_USoc %>% count(mfsize9)
```

You can see that each of the 9 categories has a significant number of observations. We shall change the name of this variable to `fsize` to make it slightly more intuitive:

```{r}
names(data_USoc)[names(data_USoc) == "mfsize9"] <- "fsize"
```

Before we continue, it is important to understand what type of variable this is. Let's use the `str` (structure) function.

```{r}
str(data_USoc$fsize)
```

You can see that this is a numeric variable.

Initially we will use the variable, however, not as a numeric, but rather as a categorical variable. So we are not really interested the numerical differences between the bin means. This means that we should change the variable type to a factor variable. We define a new variable for this reason, `fsize_f`.

```{r}
data_USoc$fsize_f <- as.factor(data_USoc$fsize)
str(data_USoc$fsize_f)
```
Looking again at `str(data_USoc$fsize_f)` we confirm that this is now a factor variable.

# Cleaning the dataset

Now we will remove data from the dataframe which have missing observations in either the `fsize` or the `lnhrpay` variable. As we will not require these observations in this lecture we will remove these observations from `data_USoc`.

```{r}
data_USoc <- data_USoc %>% filter(!is.na(lnhrpay)) %>%
                            filter(!is.na(fsize))
```

Let's produce some summary statistics. There are a number of ways to achieve this

```{r}
summary(data_USoc$lnhrpay)
summary(data_USoc$fsize)
```

We can also use the stargazer function (after selecting the two variables we are interested in)

```{r}
data_USoc %>% select(lnhrpay,fsize) %>% stargazer(type="text")
```

Let's also calculate the average hourly log pay by firm size.

```{r}
data_USoc %>% group_by(fsize) %>%
              summarise(mean_lnhrpay = mean(lnhrpay), sd_lnhrpay = sd(lnhrpay), n = n())
```

You can see that the average pay increases with firm size.

# Estimating the model

Now we will investigate whether the hourly pay correlates with the firmsize. Initially we will use the factor (categorical) version of the variable, `fsize_f`.

```{r}
mod1 <- lm(lnhrpay~fsize_f, data = data_USoc)
stargazer_HC(mod1)
```

You can see that all firm size categories have been included as dummy variables except for the smallest. This is the base category and the estimated constant term is the average value for `lnhrpay` in that base category (compare to the above table). The other coefficients are the difference in mean pay relative to the base category. As you can see the average pay in all but one of the other categories is larger than in the smallest firms.

The smallest firm category was the base category as R orders factors alphabetically/numerically and "1" comes before all of the other category labels. You may have reasons to want to re-estimate the model with a different base category. Say you want the largest category to be the base category, as in the lecture slides, then we need to change the ordering of our levels in the factor variable `fsize`. (I had to google "r factor change level order" to remind myself of how to do that.)

```{r}
data_USoc$fsize_f <- relevel(data_USoc$fsize_f, "1500")  # sets 1500 as the first level
str(data_USoc$fsize_f)
```

If we now re-estimate the above model we obtain different parameters, but in essence we are still estimating the same model and indeed the group means from the earlier table.  The lecture slides and background notes explain in more detail.

```{r}
mod2 <- lm(lnhrpay~fsize_f, data = data_USoc)
stargazer_HC(mod2)
```

In fact, you could estimate the model without the constant but a full set of variables for all the 9 categories. You need to tell R to not include a constant. You do that by adding `-1` to the model specification.

```{r}
mod3 <- lm(lnhrpay~fsize_f-1, data = data_USoc)
stargazer_HC(mod3)
```
In the absence of a constant each coefficient replicates the sample mean of the respective firm size categories.

All the above specifications essentially estimate the same model.

Recall that we changed the firm size variable into a factor variable which allowed the use of the firm size categories. What would happen if used the variable `fsize`, but as the log firmsize, `log(fsize)`. Recall that this is a numerical variable, so R uses the actual numbers reported.

```{r}
mod4 <- lm(lnhrpay~log(fsize), data = data_USoc)
stargazer_HC(mod4)
```

We see that estimated coefficient is positive (larger firms means larger wages) and statistically significant.

Let's compare the fitted values for `mod3` and `mod4`. First we add the predicted values to the dataframe

```{r}
data_USoc$pred_mod3 <- mod3$fitted.values
data_USoc$pred_mod4 <- mod4$fitted.values
```

Now we plot the predicted values for the two specifications. Recall that we only have 9 different values for the firm size.

```{r}
# pdf("Lecture5plot_R.pdf",width = 5.5, height = 4) # uncomment to save as pdf
ggplot(data_USoc, aes(x=fsize,y=pred_mod3)) +
  geom_point(color = "red") +
  geom_point(aes(y=pred_mod4),color = "blue") +
  geom_line(aes(y=pred_mod4),color = "blue") +
  ggtitle("Predicted Regression Model") +
  ylab("Predicted values") +
  xlab("Firm Size")
# dev.off() # uncomment to save as pdf
```
