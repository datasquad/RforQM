---
title: "Gun Example - Part 3 - further Diff-in-Diff"
author: "Ralf Becker"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```


## Intro

Here we are looking at replicating aspects of this paper:

Siegel et al (2019) The Impact of State Firearm Laws on Homicide and Suicide Deaths in the USA, 1991–2016: a Panel Study, J Gen Intern Med 34(10):2021–8.

* In Part 1 - Data acquisition and management, we organised the data in a new datafile saved in "US Gun_example_v3.csv". 
* In Part 2 - Initial Diff-in-Diff, we estimated a TWFE model but also an event studies model on a reduced set of treatmment and control group countries

In this part we will apply newly developed methods of inference in a Difference-in-Difference framework. They are methods that account for staggered policy implementation with potential heterogeneous policy effects.

## Load packages

Let's start by loading the packages we will use throughout this work.

```{r}
library(tidyverse)
library(readxl)
library(stringr)
library(ggplot2)
library(plm)          # for panel data
library(sandwich)     # for cluster robust standard errors
library(stargazer)    # for nice regression output
library(stringr)      # to extract strings
library(coefplot)     # to create coefficient plots
library(AER)          # to use lht
library(did)          # allowing the implementation of Callaway, Sant'Anna
library(staggered)

source("Stargazer_HC.R") # Save this function in your working directory to easily access
                         # heteroskedasticity robust regresison inference
```

## Load Data


```{r, eval = FALSE}
# ensure you know where you saved this file from Part 1
data3 <- read.csv("US Gun_example_v3.csv")

# we also load the laws codebook just in case we need to refer to it
law_data_codebook <- read_excel("../data/Firearmlaws codebook_0.xlsx")
names(law_data_codebook) = make.names(names(law_data_codebook)) # This elimnates spaces in variable names
```

```{r, echo = FALSE}
data3 <- read.csv("../data/US Gun_example_v3.csv")

# we also load the laws codebook just in case we need to refer to it
law_data_codebook <- read_excel("../data/Firearmlaws codebook_0.xlsx")
names(law_data_codebook) = make.names(names(law_data_codebook)) # This elimnates spaces in variable names
```

Let's recall what variables are included in `data3`:

```{r}
names(data3)
```

## The TWFE estimator

We create the `pol_shallissue` variable as well as log versions of the possible outcome variables (`log.fd.pc` and `log.homi.pc`). 

```{r}
data3$pol_shallissue <- 1 - data3$pol_mayissue 
data3 <- data3 %>% mutate(log.fd.pc = log(firearm.deaths.pc), log.homi.pc = log(homi.pc))
pdata <- pdata.frame(data3, index = c("State","Year")) # defines the panel dimensions
```


Before proceeding we should recall the staggered policy setup in our example.

```{r}
ggplot(data3, aes(x = Year, y = State)) + 
  geom_raster(aes(fill=pol_shallissue)) + 
  scale_fill_gradient(low="grey90", high="red") +
  labs(x="Year", y="State", title="Policy - Shall Issue Policy") 

```

The following replicates the TWFE model estimation from Part 2.

```{r}
mod_twfe1c <- lm(log.fd.pc~State+Year+pol_ubc+prop18.24+law.officers.pc+ur+vcrime.pc+alcc.pc+incarc.pc+log(Population), data = pdata)
se_twfe1c <- sqrt(diag(vcovCL(mod_twfe1c, cluster = ~ State)))

mod_twfe2c <- lm(log.fd.pc~State+Year+pol_shallissue+prop18.24+law.officers.pc+ur+vcrime.pc+alcc.pc+incarc.pc+log(Population), data = pdata)
se_twfe2c <- sqrt(diag(vcovCL(mod_twfe2c, cluster = ~ State)))

stargazer(mod_twfe1c, mod_twfe2c, keep = c("pol_ubc","pol_shallissue"), type="text", se=list(se_twfe1c,se_twfe2c), 
          digits = 6, notes="Cluster (State) Robust standard errors in parenthesis")
```

These were the results we also saw in Part 2. It is now well established that these policy estimators are biased estimators of the policy effect if the policy is implemented in a staggered manner and there is potential policy heterogeneity. The latter describes the situation when the effect of the policy is different in Illinois, where the policy was implemented in 2013, and Kansas where the policy was implemented in 2007.

## Robust Diff-in-Diff estimators

We will now look at Difference-in-Difference estimators that accommodate staggered policy timing and policy heterogeneity. This is not the place in which the details of these estimator are to be discussed, but by way of a simple (or rather simplistic) explanation we will first illustrate the root of the problem.

### Sub-sample analyses

Consider the simplified setup we used for the states that introduced the policy in 2013 (Illinois and Alabama). 

```{r}
State_sel <- c("Alabama", "Illinois", "Delaware", "Connecticut", "Rhode Island", "New York", "New Jersey", "Massachusetts", "Maryland")
pdata_sub1 <- pdata %>% filter(State %in% State_sel)
```

Now replicate the above plot with this subset.

```{r, fig.height = 2, fig.width = 6}
ggplot(pdata_sub1, aes(x = Year, y = State)) + 
  geom_raster(aes(fill=pol_shallissue)) + 
  scale_fill_gradient(low="grey90", high="red") +
  labs(x="Year", y="State", title="Policy - Shall Issue Policy") +
  guides(x = guide_axis(n.dodge = 2)) # this offsets every 2nd x axis label
```

In this set of treatment and control states the policy is only implemented in 2013, so there is no staggered set-up. This means that implementing the TWFE model for this sub-set is not problematic.


```{r}
mod_twfe1c_sub1 <- lm(log.fd.pc~State+Year+pol_ubc+prop18.24+law.officers.pc+ur+vcrime.pc+alcc.pc+incarc.pc+log(Population), data = pdata_sub1)
se_twfe1c_sub1 <- sqrt(diag(vcovCL(mod_twfe1c_sub1, type = "HC1")))

mod_twfe2c_sub1 <- lm(log.fd.pc~State+Year+pol_shallissue+prop18.24+law.officers.pc+ur+vcrime.pc+alcc.pc+incarc.pc+log(Population), data = pdata_sub1)
se_twfe2c_sub1 <- sqrt(diag(vcovCL(mod_twfe2c_sub1, type = "HC1")))

stargazer(mod_twfe1c_sub1, mod_twfe2c_sub1, keep = c("pol_ubc","pol_shallissue"), type="text", 
          se=list(se_twfe1c_sub1,se_twfe2c_sub1), 
          digits = 6, notes="Robust standard errors in parenthesis")
```

Recall that these were the results for the states that implement the policy in 2013. We now replace, in the above analysis Alabama and Illinois (the two treatment states) with Wisconsin and Iowa who both introduced the policy in 2011 and the re-estimate the TWFE model.

```{r}
State_sel <- c("Wisconsin", "Iowa", "Delaware", "Connecticut", "Rhode Island", "New York", "New Jersey", "Massachusetts", "Maryland")
pdata_sub2 <- pdata %>% filter(State %in% State_sel)
```

Now replicate the above plot with this subset. 

```{r, fig.height = 2, fig.width = 6}
ggplot(pdata_sub2, aes(x = Year, y = State)) + 
  geom_raster(aes(fill=pol_shallissue)) + 
  scale_fill_gradient(low="grey90", high="red") +
  labs(x="Year", y="State", title="Policy - Shall Issue Policy") +
  guides(x = guide_axis(n.dodge = 2)) # this offsets every 2nd x axis label
```

Thenn we re-estimate the TWFE model using this subset/

```{r}
mod_twfe1c_sub2 <- lm(log.fd.pc~State+Year+pol_ubc+prop18.24+law.officers.pc+ur+vcrime.pc+alcc.pc+incarc.pc+log(Population), data = pdata_sub2)
se_twfe1c_sub2 <- sqrt(diag(vcovCL(mod_twfe1c_sub2, type = "HC1")))

mod_twfe2c_sub2 <- lm(log.fd.pc~State+Year+pol_shallissue+prop18.24+law.officers.pc+ur+vcrime.pc+alcc.pc+incarc.pc+log(Population), data = pdata_sub2)
se_twfe2c_sub2 <- sqrt(diag(vcovCL(mod_twfe2c_sub2, type = "HC1")))

stargazer(mod_twfe1c_sub2, mod_twfe2c_sub2, keep = c("pol_ubc","pol_shallissue"), type="text", 
          se=list(se_twfe1c_sub2,se_twfe2c_sub2), 
          digits = 6, notes="Robust standard errors in parenthesis")
```
As you can see the policy effects appear similar. But if you were to repeat the exercise for the countries who implement the policy in 2007 (Kansas and Nebraska) you will find that the coefficient on the "shall policy" changes quite significantly.

```{r}
State_sel <- c("Kansas", "Nebraska", "Delaware", "Connecticut", "Rhode Island", "New York", "New Jersey", "Massachusetts", "Maryland")
pdata_sub3 <- pdata %>% filter(State %in% State_sel)
```


```{r}
mod_twfe1c_sub3 <- lm(log.fd.pc~State+Year+pol_ubc+prop18.24+law.officers.pc+ur+vcrime.pc+alcc.pc+incarc.pc+log(Population), data = pdata_sub3)
se_twfe1c_sub3 <- sqrt(diag(vcovCL(mod_twfe1c_sub3, type = "HC1")))

mod_twfe2c_sub3 <- lm(log.fd.pc~State+Year+pol_shallissue+prop18.24+law.officers.pc+ur+vcrime.pc+alcc.pc+incarc.pc+log(Population), data = pdata_sub3)
se_twfe2c_sub3 <- sqrt(diag(vcovCL(mod_twfe2c_sub3, type = "HC1")))
```

Now we only display the results for the TWFE models for the full sample TWFE and the three subsamples for the "shall issue policy".

```{r}
stargazer(mod_twfe2c, mod_twfe2c_sub1, mod_twfe2c_sub2, mod_twfe2c_sub3, 
          keep = c("pol_ubc","pol_shallissue"), 
          type="text", 
          column.labels = c("Full", "Sub1", "Sub2", "Sub3"),
          se=list(se_twfe2c,se_twfe2c_sub2,se_twfe2c_sub2,se_twfe2c_sub3), 
          digits = 6, notes="Robust standard errors in parenthesis",
          omit.stat = "F")
```

What you can  tell from this table is that in all three sub-samples the policy effect was estimated to be significantly larger than that in the full sample TWFE. The reason for the badly estimated policy effect in the full model is that the full TWFE model does not restrict itself to "clean" control groups. Consider Alabama and Illinois who introduced the policy in 2013. A full sample TWFE model basically also uses states that were previously treated (e.g. Wisconsin, Iowa, Kansas and Nebraska) as control states for Alabama and Illinois. 


### Galloway and Santa'Anna (2021)

The approach by Galloway and Santa'Anna is to restrict the analysis to only "clean" combinations of treatment and control groups, such as those in subsamples 1 to 3 above. Although you should note that for early treatment states such as Kansas and Nebraska one could add later treatment states to the control group (shortening the sample period). Once multiple estimates are obtained, they are averaged to obtain an average treatment effect for the treated. 

It should also be noted that this methodology is designed for binary policies (i.e. the policy is either implemented or not) that, once implemented, are not reversed. The identification assumption remains a parallel trends assumption, in particular the assumption that all states that are being treated would on average have the same trend in the outcome variable as the untreated states (starting from the time of the first group being treated) had they not been treated.

Additionally, as typically difference-in-difference methods do, we need to assume that policy implementations are not anticipated and that the fact a unit is being treated has no spillover effects on other units.

Here we will not discuss how exactly they perform this estimation but illustrate how to use the `did` package written by Callway and Santa'Anna. In order to apply their estimation procedure we do need one extra variable in our dataset. For each state we need to indicate in which year the policy was introduced the first time. 

We will create a new variable called `pol_shallissue_time` which takes the value of 2013 for all Alabama and Illinois observations, 2011 for all Wisconsin and Iowa observations and 200 for all Kansas and Nebraska observations and so on. For different policies this timing will be different. The following lines create `pol_shallissue_time` and `pol_ubc_time`.

We also need the year variable as a numeric variable which we need to create first as in `pdata` the `Year` variable is a factor variable. The different units (here states) also need a numeric representation. The dataset does already include the variable `State_num_code`.

```{r}
# add numeric Year variable
pdata$Year_num <- as.numeric(as.character(pdata$Year))

# for shall issue
# find the earliest implementation time
# this will only work for states that did implement policy
pdata_test <- pdata %>% filter(pol_shallissue == 1) %>% 
                        group_by(State) %>% 
                        summarise(pol_shallissue_time = min(Year_num))
# add to pdata
pdata <- merge(pdata,pdata_test, all.x = TRUE) 
# ensure that states with no policy implementation get a value of 0
pdata <- pdata %>% mutate(pol_shallissue_time = case_when(pol_shallissue_time>0 ~ pol_shallissue_time,
                                                          is.na(pol_shallissue_time)~ 0)) 

# repeat the same for universal background checks
pdata_test <- pdata %>% filter(pol_ubc == 1) %>% 
                        group_by(State) %>% 
                        summarise(pol_ubc_time = min(Year_num))
pdata <- merge(pdata,pdata_test, all.x = TRUE) 
pdata <- pdata %>% mutate(pol_ubc_time = case_when(pol_ubc_time>0 ~ pol_ubc_time,
                                                  is.na(pol_ubc_time)~ 0)) 
```

Now we can apply the Calloway and Santa'Anna estimator.

It is now straighforward to see the different treatment groups available for the two policies considered. Here we only show the table for the shall issue policy.

```{r}
table1 <- pdata %>% select(State, pol_shallissue_time) %>%  
                    unique() %>% 
                    group_by(pol_shallissue_time) %>% 
                    summarise(n = n()) %>% print()
```

There are 10 states that never implemented the policy (`pol_shallissue_time = 0`), 31 states that had the policy in place right from the first sample period (2001) and then between 1 and 3 states that introduced the "shall issue" policy during the sample period in the indicated year.

#### Without Covariates

Initially we shall estimate the model for lpog firearm deaths (`yname = "log.fd.pc"`) without any covariates other than a constant (`xformla = ~1`). The function `att_gt` further requires numeric variables representing the time and the unit (here `tname = "Year_num"`and `idname = "State_num_code"`) as well as an indicator variable indicating the group membership as defined by the time of the first policy implementation (`gname = "pol_shallissue_time"`).

```{r}
# estimate group-time average treatment effects using att_gt method
gun_shall1_attgt <- att_gt(yname = "log.fd.pc",
                        tname = "Year_num",
                        idname = "State_num_code",
                        gname = "pol_shallissue_time",
                        xformla = ~1,
                        data = pdata
                        )

# summarize the results
summary(gun_shall1_attgt)
```

In the notes to the output you can see the note `Control Group:  Never Treated`. This means that for each of the treatment groups, the control group used is the group of states that have never implemented the policy. In this case these are the 10 states with value 0 in `pol_shallissue_time`.

You can see that this model estimates a lot of coefficients as it basically estimates an event studies model for each of the five groups. It is usually more useful to visualise these parameter estimates.

```{r, out.width="100%"}
p1 <- ggdid(gun_shall1_attgt, 
            ncol = 2, 
            xgap = 4, 
            ylim = c(-0.4,0.9),
            title = "Shall-issue policy implementation by implementation year")
p1
```

This plot is equivalent to the event study plot from Part 2. In particular you can compare the plot from Part 2 with that for Group 2013.

What this plot (and `summary(gun_shall1_attgt)`) presents are group and year specific average treatment/policy effects for the treated, or in the language of the literature ATT(g,t), for group g and at time t. The red dots represent policy effects before the respective policy introduction and if the parallel trend assumption holds should all be around 0. The blue dots represent the policy effects after the respective introduction of the policy. If they deviate significantly from 0 this indicates a significant policy effect. Here we can see that there are significant policy effects for all five groups although for some groups these effects are very delayed.

Why are there only five groups? In the summary table above we saw that there were actually 6 groups with 31 states having the policy implemented from the first sample period onwards. For the group which had the policy implemented right from the start it is impossible to implement a Diff-in-Diff model and hence the data from these 31 countries are neither used as a treatment group, nor are they used as a control group.

Recall that, when we estimated a policy effect of the shall policy of 0.06 this was basically some sort of average across groups and time. In some sense you can think of this, conceptually, as an average value of all the post-policy estimates of ATT(g,t) (the blue coloured dots in the above plot), just that it has been shown that the TWFE estimator is a biased estimator of this average.

The `did` package allows you to aggregate the these in different ways.

* weighted average of all post policy ATT(g,t)s weighted by group sizes (here number of treatment states in each group), `aggte(gun_shall1_attgt, type = "simple")`
* weighted average of group ATT(g,t)s at different relative exposure times to the policy, `aggte(gun_shall1_attgt, type = "dynamic")`. This delivers the "traditional" event study plot
* average of post policy ATT(g,t)s across groups for each time period, `aggte(gun_shall1_attgt, type = "calendar")`
* average of ATT(g,t)s for each group, i.e. averaging across post policy periods, `aggte(gun_shall1_attgt, type = "group")`

Below you can see the results of these different ways to calculate average treatment effects.

```{r}
aggte(gun_shall1_attgt, type = "simple")
```
```{r}
ggdid(aggte(gun_shall1_attgt, type = "dynamic"))
```

```{r}
att_groups <- aggte(gun_shall1_attgt, type = "group")
summary(att_groups)
```

```{r}
ggdid(aggte(gun_shall1_attgt, type = "calendar"), xgap = 2)
```

As you can see there are several ways to summarise the average treatment effects. Overall summaries here suggest that the policy effect is around 0.2 as opposed to 0.08 coming from the TWFE (or 0.06 from the model with covariates). 


#### With Covariates

We now consider the inclusion of covariates. Covariates were also included in the TWFE model and then delivered a TWFE policy parameter estimate of 0.06. As we are now estimating smaller models, with fewer states in the treatment group (between one and three states implemented policies at a particular point in time), the estimation becomes more challenging and impossible if we include too many covariates. We therefore include only one, here `alcc.pc` a measure of per capita alcohol consumption in a state-year (`xformla = ~alcc.pc`).

```{r}
# estimate group-time average treatment effects using att_gt method
gun_shallcov_attgt <- att_gt(yname = "log.fd.pc",
                        tname = "Year_num",
                        idname = "State_num_code",
                        gname = "pol_shallissue_time",
                        xformla = ~alcc.pc,
                        data = pdata
                        )
```

```{r, out.width="100%"}
pcov <- ggdid(gun_shallcov_attgt, 
            ncol = 2, 
            xgap = 4, 
            ylim = c(-0.4,0.9),
            title = "Shall-issue policy implementation by implementation year, incl alcc.pc as covariate")
pcov
```

You can already see that for the group where we only had one state in the treatment group (Group 2004) we do not get any standard errors as our estimation does run out of degrees of freedom. This also indicates that even where we have confidence intervals (including our estimation without covariates above) we are conducting inference with small numbers of degrees of freedom. In such situations Calloway and Sant'Anna recommend putting more weight an aggregate estimates of the policy effect.

Here the overall aggregate:

```{r}
aggte(gun_shallcov_attgt, type = "simple")
```

Or the group aggregates:

```{r}
att_groups <- aggte(gun_shallcov_attgt, type = "group")
summary(att_groups)
```

Both estimates deliver policy effects in the area of 0.25, significantly larger than the TWFE estimates of 0.06 (or 0.08 without covariates). In Part 2 we scaled the effect to the size of the state of Texas and concluded that effect of moving from a may issue to a shall issue policy was around 300 additional deaths per year in Texas. With the new coefficient estimates this number increases to around 1,020 extra deaths by firearm.

#### Other outcome and policy measures

Let us check whether we obtain similar results when we use the (log) number of homicides per 100,000 (`homi.pc`) as the outcome variable.

```{r}
# estimate group-time average treatment effects using att_gt method
gun_shall1_homi_attgt <- att_gt(yname = "log.homi.pc",
                        tname = "Year_num",
                        idname = "State_num_code",
                        gname = "pol_shallissue_time",
                        xformla = ~1,
                        data = pdata
                        )
```

```{r}
aggte(gun_shall1_homi_attgt, type = "simple")
```

Again we obtain a significantly larger estimate (0.16 as opposed to 0.05) but it remains not significantly different from 0 (at $\alpha = 0.05$).

We also analyse the policy of introducing universal background checks. When applying TWFE we obtained policy effect coefficients of between -0.06 and -0.08. They were always estimated to not be statistically significant.

```{r}
# estimate group-time average treatment effects using att_gt method
gun_shall1_ubc_attgt <- att_gt(yname = "log.fd.pc",
                        tname = "Year_num",
                        idname = "State_num_code",
                        gname = "pol_ubc_time",
                        xformla = ~1,
                        data = pdata
                        )
```

```{r}
aggte(gun_shall1_ubc_attgt, type = "simple")
```

The coefficient is somewhat larger in absolute size and now statistically significant at the 95% confidence level.

When changing the outcome variable to (log) homicides per 100,000 (`log.homi.pc`) we obtain the following result:

```{r}
# estimate group-time average treatment effects using att_gt method
gun_shall1_ubc_homi_attgt <- att_gt(yname = "log.homi.pc",
                        tname = "Year_num",
                        idname = "State_num_code",
                        gname = "pol_ubc_time",
                        xformla = ~1,
                        data = pdata
                        )
```

```{r}
aggte(gun_shall1_ubc_homi_attgt, type = "simple")
```

When evaluating the effect of the universal background check policy on homicide deaths the effect remains not statistically different from 0. 


### Roth and Sant'Anna (2021)

This methodology bases on a fundamentally different identification assumption compared to traditional difference-in-difference methods that essentially make a parallel trends assumption of sorts. This methodology has what is often called a "design-based" justification. The identification relies on the timing of the policy implementation to be random. 

It is therefore important that, when applying this methodology, that a discussion of why the timing of the policy implementation can be seen as random. Beyond that, a discussion of parallel trends is not required.

One feature of this methodology is that it is possible to deal with situation sin which there are no never treated units. For instance you may have the situation in which all states in a country impose a certain policy and the only thing that varies is the timing of the policy introduction. One consequence of such a setup is that this methodology will not estimate group and year specific average treatment/policy effects for the treated, $ATT(g,t)$, where, recall $g$ indicated the first year of the policy implementation. This methodology does identify the effect, at time $t$, of moving the policy introduction from the introduction time $g$ to another introduction time $g'$, $ATE(g,g',t)$. It is possible, but not required, to include units that never implement the policy (for which $g=\infty$) in which case one could look at $ATE(g,\infty,t)$, the effect of being treated at time $g$ as compared to being never treated $g'=\infty$.

## Summary

Here we demonstrated, using an empirical example, why TWFE estimates can be biased. In this case they are estimated to be too small. Adjusting the methodology to ... to be finalised.



## Reading

Callaway, B., Sant’Anna, P.H.C. (2021) Difference-in-Differences with multiple time periods. Journal of Econometrics 225, 200–230.

Roth, J. and Sant'Anna, P.H.C. (2021) Efficient Estimation for Staggered Rollout Designs. [https://arxiv.org/abs/2102.01291](arXiv:2102.01291) [econ, math, stat].

Roth, J. and Sant'Anna, P.H.C., Bilinski, A. and Poe, J. (2023), What’s trending in difference-in-differences? A synthesis of
the recent econometrics literature, Journal of Econometrics, 235,  2218-2244.
